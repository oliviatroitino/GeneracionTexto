{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_ahxalS_tMt"
      },
      "source": [
        "## Setup paquetes y Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "CyLNCN5Q8jNE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-dPaX2C_xSW"
      },
      "source": [
        "## Descarga y preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H9BVBBiB4ZK"
      },
      "source": [
        "Hay cambios del notebook de partida (de encoding `utf-8` a `latin-1`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duysNv6Y_ztb",
        "outputId": "efc970c2-1cc3-4fd9-fed2-ed8824eaaced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longitud del texto:        107332 carácteres\n",
            "El texto está compuesto de estos 80 carácteres:\n",
            "['\\n', '\\r', ' ', '!', '\"', '(', ')', ',', '-', '.', '1', '4', '5', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '{', '}', '¡', '«', '»', '¿', 'É', 'á', 'é', 'ê', 'í', 'ñ', 'ó', 'ú', 'ü']\n"
          ]
        }
      ],
      "source": [
        "texto = open(\"3_textos_literatura_española/Lazarillo-De-Tormes.txt\", 'rb').read().decode(encoding='utf-8')\n",
        "print('Longitud del texto:        {} carácteres'.format(len(texto)))\n",
        "\n",
        "vocab = sorted(set(texto))\n",
        "\n",
        "print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n",
        "print (vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sZ3XIMVCFdh"
      },
      "source": [
        "### Procesamiento de los textos\n",
        "#### Mapeo de caracteres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of1auErLCHFP",
        "outputId": "15a85016-4fee-4dda-d677-4847676221ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  '\\n':   0,\n",
            "  '\\r':   1,\n",
            "  ' ' :   2,\n",
            "  '!' :   3,\n",
            "  '\"' :   4,\n",
            "  '(' :   5,\n",
            "  ')' :   6,\n",
            "  ',' :   7,\n",
            "  '-' :   8,\n",
            "  '.' :   9,\n",
            "  '1' :  10,\n",
            "  '4' :  11,\n",
            "  '5' :  12,\n",
            "  ':' :  13,\n",
            "  ';' :  14,\n",
            "  '?' :  15,\n",
            "  'A' :  16,\n",
            "  'B' :  17,\n",
            "  'C' :  18,\n",
            "  'D' :  19,\n",
            "  'E' :  20,\n",
            "  'F' :  21,\n",
            "  'G' :  22,\n",
            "  'H' :  23,\n",
            "  'I' :  24,\n",
            "  'J' :  25,\n",
            "  'L' :  26,\n",
            "  'M' :  27,\n",
            "  'N' :  28,\n",
            "  'O' :  29,\n",
            "  'P' :  30,\n",
            "  'Q' :  31,\n",
            "  'R' :  32,\n",
            "  'S' :  33,\n",
            "  'T' :  34,\n",
            "  'U' :  35,\n",
            "  'V' :  36,\n",
            "  'Y' :  37,\n",
            "  'Z' :  38,\n",
            "  '_' :  39,\n",
            "  'a' :  40,\n",
            "  'b' :  41,\n",
            "  'c' :  42,\n",
            "  'd' :  43,\n",
            "  'e' :  44,\n",
            "  'f' :  45,\n",
            "  'g' :  46,\n",
            "  'h' :  47,\n",
            "  'i' :  48,\n",
            "  'j' :  49,\n",
            "  'k' :  50,\n",
            "  'l' :  51,\n",
            "  'm' :  52,\n",
            "  'n' :  53,\n",
            "  'o' :  54,\n",
            "  'p' :  55,\n",
            "  'q' :  56,\n",
            "  'r' :  57,\n",
            "  's' :  58,\n",
            "  't' :  59,\n",
            "  'u' :  60,\n",
            "  'v' :  61,\n",
            "  'x' :  62,\n",
            "  'y' :  63,\n",
            "  'z' :  64,\n",
            "  '{' :  65,\n",
            "  '}' :  66,\n",
            "  '¡' :  67,\n",
            "  '«' :  68,\n",
            "  '»' :  69,\n",
            "  '¿' :  70,\n",
            "  'É' :  71,\n",
            "  'á' :  72,\n",
            "  'é' :  73,\n",
            "  'ê' :  74,\n",
            "  'í' :  75,\n",
            "  'ñ' :  76,\n",
            "  'ó' :  77,\n",
            "  'ú' :  78,\n",
            "  'ü' :  79,\n"
          ]
        }
      ],
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlXmg61nDxFT"
      },
      "source": [
        "Pasamos cada texto a un array de enteros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IHo-ePmDwih",
        "outputId": "c1e658c9-f6bd-41b5-9c97-535d76da2982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "texto : 'LA VIDA DE LAZARILLO DE TORMES Y DE SUS FORTUNAS Y'\n",
            "'LA VIDA DE LAZARILLO DE TORMES Y DE SUS FORTUNAS Y'\n"
          ]
        }
      ],
      "source": [
        "text_as_int = np.array([char2idx[c] for c in texto])\n",
        "\n",
        "print ('texto : {}'.format(repr(texto[:50])))\n",
        "print ('{}'.format(repr(texto[:50])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMTjafW0Eaz2"
      },
      "source": [
        "### Preparación de los datos para entrenar la RNN\n",
        "\n",
        "Para entrenar el modelo creamos un conjunto de datos con el contenido de text_as_init. Para ello utilizamos la función tf.data.Dataset.from_tensor_slices.\n",
        "A este conjunto de datos lo dividiremos en secuencias de seq_length+1 al aplicar el método batch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "9gOSC4lCFY8y"
      },
      "outputs": [],
      "source": [
        "# Creamos una función `split_input_target` que devolverá el conjunto de datos\n",
        "# de entrenamiento (los datos de entrada como los datos de salida)\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "#Agrupamos los dataset en batches de 64 .\n",
        "# Así tendriamos los datos de entrenamiento con batches compuestos de 64 parejas\n",
        "# de secuencias de 100 integers de 64 bits\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv39xu08EfGl",
        "outputId": "5abe4904-bf33-480a-cc21-9a64de6b43ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'LA VIDA DE LAZARILLO DE TORMES Y DE SUS FORTUNAS Y ADVERSIDADES\\r\\nAutor desconocido.\\r\\nEdición de Burgo'\n",
            "'s, 1554.\\r\\n{Interpolaciones de la edición de Alcalá}\\r\\n_cursiva_\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nPrólogo\\r\\n\\r\\n\\r\\n\\r\\nYo por bien te'\n",
            "'ngo que cosas tan señaladas, y por ventura nunca oídas ni vistas, vengan a noticia de muchos y no se '\n",
            "'entierren en la sepultura del olvido, pues podría ser que alguno que las lea halle algo que le agrade'\n",
            "', y a los que no ahondaren tanto los deleite; y a este propósito dice Plinio que no hay libro, por ma'\n",
            "'lo que sea, que no tenga alguna cosa buena; mayormente que los gustos no son todos unos, mas lo que u'\n",
            "'no no come, otro se pierde por ello. Y así vemos cosas tenidas en poco de algunos, que de otros no lo'\n",
            "' son. Y esto, para ninguna cosa se debría romper ni echar a mal, si muy detestable no fuese, sino que'\n",
            "' a todos se comunicase, mayormente siendo sin perjuicio y pudiendo sacar della algún fruto; porque si'\n",
            "' así no fuese, muy pocos escribirían para uno solo, pues no se hace sin trabajo, y quieren, ya que lo'\n",
            "\n",
            "\n",
            "\n",
            "Input data:  'LA VIDA DE LAZARILLO DE TORMES Y DE SUS FORTUNAS Y ADVERSIDADES\\r\\nAutor desconocido.\\r\\nEdición de Burg'\n",
            "Target data: 'A VIDA DE LAZARILLO DE TORMES Y DE SUS FORTUNAS Y ADVERSIDADES\\r\\nAutor desconocido.\\r\\nEdición de Burgo'\n",
            "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n",
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "seq_length = 100\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))\n",
        "\n",
        "#Aplicamos split_input_target a todas las secuencias utilizando el método map()\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Los dataset contienen un conjunto de parejas (100 caracteres del texto original, la correspondiente salida ). Vamos a mostrar la primera pareja.\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))\n",
        "\n",
        "  print(dataset)\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print (dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzc_abq3Gtra"
      },
      "source": [
        "### Construcción del modelo RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "s9Uxb2ALG0kv"
      },
      "outputs": [],
      "source": [
        "#Crearemos una función que cree un modelo RNN con tres capas\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = Sequential()\n",
        "  #Añadimos la capa de tipo word embedding\n",
        "  model.add(Embedding(input_dim=vocab_size,\n",
        "                      output_dim=embedding_dim,\n",
        "                      #batch_input_shape=[batch_size, None] Deprecated\n",
        "                      ))\n",
        "  #Añadimos la capa de tipo LSTM\n",
        "  model.add(LSTM(rnn_units,\n",
        "                 return_sequences=True,\n",
        "                 stateful=True,\n",
        "                 recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "  #Añadimos la capa de tipo Dense\n",
        "  model.add(Dense(vocab_size))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "CXSrXhXHG-Vh"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "YkxLgKFMHLoB",
        "outputId": "db74e307-2006-44f7-cf33-1405503bbebf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH80YLm9IC5O",
        "outputId": "2b325b7a-55ff-4d41-f42e-6152e52a4ef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: (64, 100) # (batch_size, sequence_length)\n",
            "Target: (64, 100) # (batch_size, sequence_length)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n",
        "  print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfJiDVjVIFMx",
        "outputId": "a39a8a7b-92e1-4a91-edba-8c97a5c515cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction :  (64, 100, 80) # (batch_size, sequence_length, vocab_size)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-24 21:28:10.595680: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(\"Prediction : \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "j8ODv1oxIGxL"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s5oc_-5Il7k",
        "outputId": "8632e78a-22ca-4369-feb9-c1db9a06cb78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[61 42 26 77 25 12 55 76 45 64 26 37 65 41 67 24 55 64 50 79  3 58 51 61\n",
            " 53 59 29  0  7 64 41  1 20 57 46 33 61 10 17 26 45 56 77 69 25 43 45 43\n",
            " 23 59 20 78 55 77 53 36  0 72 72 30 77  6 57 47 18 76 79 51 58 39 27 59\n",
            " 37 13 70 20 75 15 77 23 74 14  2 29 50 47 10 47 45 15 49  7 25 64 34 39\n",
            "  8  1 41 16]\n"
          ]
        }
      ],
      "source": [
        "print(sampled_indices_characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJENmFNXL0Io"
      },
      "source": [
        "### Entrenamiento del modelo RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "uKqSJOP_Cpso"
      },
      "outputs": [],
      "source": [
        "#Creamos la función de perdida, usaremos el categorical pues estamos considerando datos categóricos\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "YPNOYQq9Cpu-"
      },
      "outputs": [],
      "source": [
        "#Compilamos el modelo\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "qqxhp8m-Cpw1"
      },
      "outputs": [],
      "source": [
        "#configuramos los checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints_Lazarillo'\n",
        "\n",
        "# nombre fichero\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementación EarlyStopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=10,\n",
        "    min_delta=0.01,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "SROaEjLNDCuF",
        "outputId": "7ca79371-a2d0-4f52-de56-d96f2755f556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 601ms/step - loss: 3.6581\n",
            "Epoch 2/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 596ms/step - loss: 2.4085\n",
            "Epoch 3/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 624ms/step - loss: 2.1887\n",
            "Epoch 4/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 635ms/step - loss: 2.0727\n",
            "Epoch 5/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 613ms/step - loss: 2.0008\n",
            "Epoch 6/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 619ms/step - loss: 1.9467\n",
            "Epoch 7/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 619ms/step - loss: 1.8978\n",
            "Epoch 8/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 626ms/step - loss: 1.8619\n",
            "Epoch 9/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 645ms/step - loss: 1.8241\n",
            "Epoch 10/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 646ms/step - loss: 1.7929\n",
            "Epoch 11/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 664ms/step - loss: 1.7587\n",
            "Epoch 12/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 631ms/step - loss: 1.7235\n",
            "Epoch 13/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 626ms/step - loss: 1.6817\n",
            "Epoch 14/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 641ms/step - loss: 1.6633\n",
            "Epoch 15/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 605ms/step - loss: 1.6359\n",
            "Epoch 16/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 618ms/step - loss: 1.6019\n",
            "Epoch 17/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 639ms/step - loss: 1.5712\n",
            "Epoch 18/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 641ms/step - loss: 1.5224\n",
            "Epoch 19/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 622ms/step - loss: 1.5027\n",
            "Epoch 20/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 626ms/step - loss: 1.4683\n",
            "Epoch 21/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 610ms/step - loss: 1.4243\n",
            "Epoch 22/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 619ms/step - loss: 1.3805\n",
            "Epoch 23/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 629ms/step - loss: 1.3326\n",
            "Epoch 24/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 611ms/step - loss: 1.2864\n",
            "Epoch 25/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 634ms/step - loss: 1.2334\n",
            "Epoch 26/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 637ms/step - loss: 1.1766\n",
            "Epoch 27/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 637ms/step - loss: 1.1122\n",
            "Epoch 28/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 621ms/step - loss: 1.0507\n",
            "Epoch 29/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 617ms/step - loss: 0.9952\n",
            "Epoch 30/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 622ms/step - loss: 0.9244\n",
            "Epoch 31/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 635ms/step - loss: 0.8632\n",
            "Epoch 32/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 645ms/step - loss: 0.7960\n",
            "Epoch 33/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 625ms/step - loss: 0.7255\n",
            "Epoch 34/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 622ms/step - loss: 0.6753\n",
            "Epoch 35/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 609ms/step - loss: 0.6205\n",
            "Epoch 36/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 613ms/step - loss: 0.5651\n",
            "Epoch 37/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 625ms/step - loss: 0.5196\n",
            "Epoch 38/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 625ms/step - loss: 0.4870\n",
            "Epoch 39/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 616ms/step - loss: 0.4522\n",
            "Epoch 40/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 618ms/step - loss: 0.4164\n",
            "Epoch 41/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 593ms/step - loss: 0.3975\n",
            "Epoch 42/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 617ms/step - loss: 0.3757\n",
            "Epoch 43/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 638ms/step - loss: 0.3571\n",
            "Epoch 44/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 621ms/step - loss: 0.3403\n",
            "Epoch 45/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 633ms/step - loss: 0.3249\n",
            "Epoch 46/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 641ms/step - loss: 0.3131\n",
            "Epoch 47/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 645ms/step - loss: 0.2966\n",
            "Epoch 48/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 647ms/step - loss: 0.2919\n",
            "Epoch 49/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 629ms/step - loss: 0.2801\n",
            "Epoch 50/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 637ms/step - loss: 0.2731\n",
            "Epoch 51/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 631ms/step - loss: 0.2630\n",
            "Epoch 52/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 630ms/step - loss: 0.2578\n",
            "Epoch 53/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 633ms/step - loss: 0.2543\n",
            "Epoch 54/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 621ms/step - loss: 0.2464\n",
            "Epoch 55/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 623ms/step - loss: 0.2395\n",
            "Epoch 56/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 612ms/step - loss: 0.2338\n",
            "Epoch 57/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 641ms/step - loss: 0.2305\n",
            "Epoch 58/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 631ms/step - loss: 0.2271\n",
            "Epoch 59/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 608ms/step - loss: 0.2172\n",
            "Epoch 60/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 628ms/step - loss: 0.2177\n",
            "Epoch 61/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 661ms/step - loss: 0.2102\n",
            "Epoch 62/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 615ms/step - loss: 0.2098\n",
            "Epoch 63/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 616ms/step - loss: 0.2072\n",
            "Epoch 64/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 643ms/step - loss: 0.2025\n",
            "Epoch 65/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 638ms/step - loss: 0.2008\n",
            "Epoch 66/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 639ms/step - loss: 0.1939\n",
            "Epoch 67/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 621ms/step - loss: 0.1916\n",
            "Epoch 68/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 632ms/step - loss: 0.1937\n",
            "Epoch 69/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 641ms/step - loss: 0.1878\n",
            "Epoch 70/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 651ms/step - loss: 0.1862\n",
            "Epoch 71/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 612ms/step - loss: 0.1829\n",
            "Epoch 72/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 614ms/step - loss: 0.1837\n",
            "Epoch 73/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 661ms/step - loss: 0.1810\n",
            "Epoch 74/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 644ms/step - loss: 0.1801\n",
            "Epoch 75/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 655ms/step - loss: 0.1729\n",
            "Epoch 76/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 637ms/step - loss: 0.1731\n",
            "Epoch 77/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 624ms/step - loss: 0.1728\n",
            "Epoch 78/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 649ms/step - loss: 0.1725\n",
            "Epoch 79/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 629ms/step - loss: 0.1670\n",
            "Epoch 80/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 647ms/step - loss: 0.1645\n",
            "Epoch 81/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 665ms/step - loss: 0.1636\n",
            "Epoch 82/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 643ms/step - loss: 0.1609\n",
            "Epoch 83/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 634ms/step - loss: 0.1615\n",
            "Epoch 84/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 657ms/step - loss: 0.1596\n",
            "Epoch 85/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 632ms/step - loss: 0.1583\n",
            "Epoch 86/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 643ms/step - loss: 0.1523\n",
            "Epoch 87/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 633ms/step - loss: 0.1553\n",
            "Epoch 88/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 642ms/step - loss: 0.1480\n",
            "Epoch 89/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 646ms/step - loss: 0.1536\n",
            "Epoch 90/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 631ms/step - loss: 0.1486\n",
            "Epoch 91/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 630ms/step - loss: 0.1458\n",
            "Epoch 92/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 634ms/step - loss: 0.1510\n",
            "Epoch 93/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 618ms/step - loss: 0.1451\n",
            "Epoch 94/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 648ms/step - loss: 0.1436\n",
            "Epoch 95/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 640ms/step - loss: 0.1470\n",
            "Epoch 96/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 650ms/step - loss: 0.1461\n",
            "Epoch 97/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 664ms/step - loss: 0.1484\n",
            "Epoch 98/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 672ms/step - loss: 0.1428\n",
            "Epoch 99/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 664ms/step - loss: 0.1391\n",
            "Epoch 100/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 660ms/step - loss: 0.1412\n"
          ]
        }
      ],
      "source": [
        "#Entrenamos el modelo\n",
        "EPOCHS=100\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback, early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "UwLoIf-eJNDH"
      },
      "outputs": [],
      "source": [
        "model.save(\"model_lazarillo_100_2025.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Mk5PTDmwAqsJ"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras import losses # Import the losses module\n",
        "\n",
        "# Assuming your original loss function was, for example, binary_crossentropy\n",
        "loaded_model = load_model(\"model_lazarillo_100_2025.keras\",\n",
        "                          custom_objects={'loss': losses.sparse_categorical_crossentropy})\n",
        "# or if it was a custom loss function\n",
        "# loaded_model = load_model(\"model_paquita_100_2024.keras\", custom_objects={'loss': my_custom_loss_function})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = build_model(len(vocab), embedding_dim, rnn_units, batch_size=1)\n",
        "input_shape = (1, 100)  # Replace 100 with your actual sequence length\n",
        "model.build(input_shape=input_shape) # Or model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.load_weights(\"model_lazarillo_100_2025.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Creamos una función generar_texto que generará texto a partir de una palabra de partida\n",
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 1000\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "\n",
        "  # temperature = 0.7 # cuanto mas alto el numero, mas directa la salida de los logits\n",
        "  temperature = 0.3\n",
        "\n",
        "#  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yo, señor, aunque soy hijo de padres humildese que amos tú esta hora entró una vieja que ensalmaba, y los vecinos, y comiénzanme a quitar trapos de la cabeza y viejo al del con el cabo de la capa sobre el lado izquierdo, sacó una llave de la manga y abrió su puerta a los que en ella entraban, aunque dentro della estaba un patio pequeño y razonables cámaras.\n",
            "\n",
            "Desque tan recio como si diera con una gran calabaza, y cayó luego para atrás, así con ella, había muerto en la de los Gelves, y que ella confiaba en Dios no saldría peor hombre que desea mucho el provecho de las ánimas; mas pregunten a su merced si le pesa cuando le dicen al altoración y decir:\n",
            "\n",
            "\"¿Qué diremos a esto? ¡Nunca haber sentido ratones en esta casa sino agor de la Sagra de Toledo había predicado dos o tres días, haciendo sus acostumbradas diligencias, y decía:\n",
            "\n",
            "\"¿Qué tienes este había tenido a buscar clavos por la casa y por las paredes y tablillas a atapárselos. Venida la noche y su reposo, y también porque consideren los que heredaron nobles estados cuán po\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Yo, señor, aunque soy hijo de padres humildes\"))\n",
        "\n",
        "# print(generate_text(model, start_string=u\"Cuando llegamos al mesón,\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intentos básicos\n",
        "## Intento 1.1: 300 épocas y 0.4 de temperatura\n",
        "```\n",
        "Yo, señor, aunque soy hijo de padres humildes alegres del arcaz, sentí que mi amo dormía, porque lo mostraba con roncar y en unos resoplidos grandes bien aquel día, maldito el gusto yo tomaba en ello, ni en aquellos tres días torné en mi color; y me demediar dende en adelante la triste vida. Y así estuve con ello aquel día y otro gozoso. Mas no estaba prestada una ratonera, y con cortezas de queso que a los vecinos pedía, contino el gato estaba armados la sepultura. Pues si deste desisto y doy en otro más bajo, ¿qué será sino fenecer?\"\n",
        "\n",
        "Con esto no por No mires a aquél que no sabe lo que hace ni dice; mas la injuria a ti hecha, te suplico, y por justicia y declarar a voces sus delitos: pregonero, hablando en buen romance, en el cual oficia a ayudar y a defender la entrada. El cual algo alterado, pensando que fuese otra cosa, me dijo:\n",
        "\n",
        "\"Lázaro, llega el oído a este toro, y oirás gran ruido dentro dél.\"\n",
        "\n",
        "Yo simpla lumbre. Y, ya que hubo acabado la misa y echada la bendición, tomóla con un pañizuelo, bien envuelta la contenta\n",
        "```\n",
        "### Observaciones:\n",
        "Es más coherente que el modelo de la Celestina, aunque si muestra posibilidad de overfitting, porque hay frases completas que las saca directo del texto. Habiendo ya mejorado el modelo de la Celestina, aplico ya directamente dichas mejoras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intentos con cambios\n",
        "### EarlyStopping\n",
        "Agregamos `EarlyStopping` por lo frecuente que es la repetición en el modelo de los intentos anteriores. Siguiendo con 300 épocas, el entrenamiento ahora frena temprano. Por ejemplo, en la primera ejecución con 300 épocas frena en la época 89 con una pérdida de 0.2089.\n",
        "```\n",
        "Epoch 89/300\n",
        "58/58 ━━━━━━━━━━━━━━━━━━━━ 32s 552ms/step - loss: 0.2089\n",
        "```\n",
        "Esto indica que el modelo había dejado de mejorar significativamente y que continuar entrenando hubiera sido ineficiente y contraproducente por overfitting.\n",
        "### BatchNormalization\n",
        "Agregamos `BatchNormalization` porque estabiliza y acelera el entrenamiento al normalizar la salida de la capa `Dense`. Esto mejora la propagación del gradiente, reduce la sensibilidad a la inicialización de pesos y regulariza el modelo. También permite que la red entrene con mayor estabilidad al combinarse con activaciones como `ReLU.`\n",
        "### Dropout\n",
        "Bajamos el dropout porque el valor original (0.5) era demasiado agresivo y podía estar dificultando el aprendizaje de patrones. Al reducirlo a 0.3, se mantiene cierta regularización para prevenir el sobreajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intento 1.1: 300 épocas y 0.5 temperatura\n",
        "```\n",
        "Yo, señor, aunque soy hijo de padres humildes, mas no lo hice sin no me lo tuviera más altos, como yo, no les han de hablar menos de: «Beso las manos de vuestra merced», o por lo menos las cosas de la honra, en que el día de hoy está todo el caudal de los hombres de bien. Pues te ha de mantenerto, pienso que me sintió, y dende en adelante mudó propósito, y asentaba su jarro entre las piernas, teniendo con el fino muy a tendido des veces, hablando con reverencia de V.M., porque está ella delante.\"\n",
        "\n",
        "Entonces mi mujer echó juramente las pajas do yo estaba en el púlpito de rodillas, las manos y los ojos puestos en el cielo, transportado en la de aquella marerdad puedo decir nacido en el río. Pues siendo yo niño de ocho años, achacaron a mi padre ciertas sabido como pensando con ellos parcial, y cuánto más hicieron los que, siéndoles contraria, con fuerza y maña remando, me parecía que hacía sinjusticia en no se las reír.\n",
        "\n",
        "Y en cuanto esto pasaba, a la memoria me vinieron a reñir y a haber malas palabras. Él llamó al alguacil ladr\n",
        "```\n",
        "### Observaciones\n",
        "Repite mucho texto literal del original, incluso frases largas enteras. Aunque la temperatura es alta, no genera nada especialmente creativo ni distinto, solo mezcla mal partes ya vistas. Probé con otras temperaturas y es igual: copia y pega.\n",
        "\n",
        "## Intento 1.2: 50 épocas y 0.2\n",
        "```\n",
        "Yo, señor, aunque soy hijo de padres humildes, y hijos malas y partendose en camino y manera provechosa; y con favor que tuve de amigos y señores, y allí algunas malas con el deseo, en tanto que el ciego sacaba de la bolsa el dinero, saqué la longaniza y muy presto me vino a tan buena recia, y aunque mozo por mejor decir, morí. De la taberna nunca le traje una blanca de vino, solor mi amo visto el daño así del pan como del agujero que yo había hecho, y comenzó a dar a los diaba de haber llevado muy buenas lanzas. ¿Qué hiciera que en la calle andaba con esto acos mis pajas, y para todos sus de las cuales él tando con el diese el de antes una caba de los amos que yo hallaba y había por bien de que ella entrase y saliese, de noche y de día, pues estaba biendo y decirle en ella cuerta de la senan de otras tantas perdeciose en falsar con las cuales daba y hallé en el cuel de la bula tomaban. Visto por el asunto de mi amo lo que pasaba y mus cantenos y en el ciego, la tenía tan hecha bolsa que me acaeció tener en el culcil diente de su\n",
        "```\n",
        "### Observaciones\n",
        "Aunque entrenado menos, sigue repitiendo mucho. Con temperatura baja se vuelve todavía más pegado al corpus original, y muchas frases están cortadas o no llegan a ningún lado. No hay mucha invención ni combinación original, simplemente junta partes conocidas sin demasiada coherencia.\n",
        "\n",
        "## Intento 1.3: 50 épocas y 0.25\n",
        "```\n",
        "Yo, señor, aunque soy hijo de padres humildes, y hijos malas y partendose en camino y manera provechosa; y con favor que tuve de amigos y señores, y al mientro y tiene a entenria de mi casa y la tristeza y silencio de los moradores, tanto que nos acaeció estar dos o tres días y dornido en su costado por mi remedio un buen agujero. Esto es a las alguacil suelo, que yo puesto en pie con mi desdicha, despertando a este lacerado de mi amo y poniéndole más diligencia, dellos. Si deseo y por lo que toca a mi honra, aunque bien creo que será secreto, según lo poco que en este pueblo sobre el caño como de la conter. No es por más de una paja salido y descuidar, pensando que hallaría un buen asiento, mas no me ha sucedido como pensé.\n",
        "\n",
        "\"Señor, de mí -dije yo- ninguna pena tenga vuestra merced, que sé pasar una noche y aun más, si es verdad lo que yo digo y bien porque me sería a grandes voces, llamándome, procuró recordarme. Mas como me tocase con las manos, tentó lo mucha sanga Dios y aun más, porque a mí con amenazas me preguntaban, y \n",
        "```\n",
        "\n",
        "### Observaciones\n",
        "Mejor que el anterior en variedad, pero igual se nota que tira frases que ya aparecían en el texto. No hay una estructura clara.\n",
        "\n",
        "## Intento 1.4.1: 100 épocas y 0.25\n",
        "```\n",
        "Yo, señor, aunque soy hijo de padres humildese que en las guardas nada de la suya diferenciaba. Fue luego a proballa, y con ella probó el maleficio y la negra que llaman honra lo que por vos no sufrirían!\"\n",
        "\n",
        "Ansí estaba yo a la puerta, mirando y con el canciento que le alcanzaron lo que él en un año no alcanzara: pienso que fueron doce o trece reales. Y él les dio lo noche y tan pía la mejor gustar el sabroso licor, sintió el desesperado ciego que agora tenía tiempo de tomar de mí venganza que el sobresaltado de mi amo lo oyó y creyó sin duda ser el silbo de la culebra; y cierto lo demosido, porque de hombre os habéis de convertir en malilla y si no. «Andá con Dios» os dicen. Y las más veces hacía del dormido, y en las mañas decíame él:\n",
        "\n",
        "\"Esta noche, mozo, ¿no sentiste nada? y había proción de sí llevaría har a aquel mezquino amo, mas por dos cosas lo dejaba: la primera, por no me atrever a mis piernas, por tener en las piernas de pura hambre. Vime claramente ir a la sepultura, si Dios y mi saber no había ninguna cosa de comer\n",
        "```\n",
        "## Intento 1.4.2: distinta start_string para probar\n",
        "```\n",
        "Cuando llegamos al mesón, a no había muerto, por quedar bien vezado de la hartura, tornando a mi cuotidiana hambre, más lo sentía algo que adobar.\n",
        "\n",
        "\"En mí teníades bien que hacer, y no haríades poco si me remediásedes\", dijo mi amo y que encima del altar había, el cual habían traído para calentarse las manos porque hacía gran frío, me quería bien con el curado remedio, porque ya la caridad se subió al cielo, topóme Dios con un escudero que iba por la calle con la mano. Como tomase las rebanadas y mordiese en ellas pensando también llevar parte de la longaniza, y no pareciendo ellas pudiera negar la demanda. Pluguiera a Dios que lo hubiera hecho, y con mucha priesa fue a buscar lumbre. Y llega aquí a nuestra casa, y le damos de comer lo que podemos por amor de Dios, y a las noches se inventario, preguntándome qué tenía.\n",
        "\n",
        "\"Señores -dije yo-, lo que este mi amo tiene, según él me di con ellos parcial, y cuánto más hicieron los que, siéndoles contraria, con fuerza y maña remando, si no, verá ha y todo lo que e\n",
        "```\n",
        "### Observaciones\n",
        "Este es el que sale mejor. Todavía hay cosas que parecen sacadas del texto, pero ya combina frases con más libertad y arma algo que suena un poco más fluido.\n",
        "\n",
        "## Intento 1.5.1: 100 épocas y 0.3\n",
        "```\n",
        "Yo, señor, aunque soy hijo de padres humildese que amos tú esta hora entró una vieja que ensalmaba, y los vecinos, y comiénzanme a quitar trapos de la cabeza y viejo al del con el cabo de la capa sobre el lado izquierdo, sacó una llave de la manga y abrió su puerta a los que en ella entraban, aunque dentro della estaba un patio pequeño y razonables cámaras.\n",
        "\n",
        "Desque tan recio como si diera con una gran calabaza, y cayó luego para atrás, así con ella, había muerto en la de los Gelves, y que ella confiaba en Dios no saldría peor hombre que desea mucho el provecho de las ánimas; mas pregunten a su merced si le pesa cuando le dicen al altoración y decir:\n",
        "\n",
        "\"¿Qué diremos a esto? ¡Nunca haber sentido ratones en esta casa sino agor de la Sagra de Toledo había predicado dos o tres días, haciendo sus acostumbradas diligencias, y decía:\n",
        "\n",
        "\"¿Qué tienes este había tenido a buscar clavos por la casa y por las paredes y tablillas a atapárselos. Venida la noche y su reposo, y también porque consideren los que heredaron nobles estados cuán po\n",
        "```\n",
        "## Intento 1.5.2:\n",
        "```\n",
        "Cuando llegamos al mesón, aunque decía se fiaban por un año, no aprovechaba y que estaban tan rebeldes en tomarla y que saba a los a parecía casa encantada. Estando así, díjome:\n",
        "\n",
        "\"Tú, mozo, ¿has comido?\"\n",
        "\n",
        "\"No, señor -dije yo-, que eso no me dejaba de lo necesario. Digo verdad: si con mi serto que hábiera de manera que antes que el mal ciego sacase de mi boca su trompa, tal alteración sintió mi estado andaba murmurando de las bulas, diciendo como eran falsas y que el mesmo alguacil riñendo lo había de un agua el de mano y diome una gran calabazada en el diablo del toro, que más de tres días me duró el dolor de la boca, y dio muchas veces, por llevar a la posada con que él lo pasase, yo lo pasaba mal. Porque una mañana, levantos, con el cual probaré bien su suficiencia.\n",
        "\n",
        "En un lacerada que todo fue acabado y la gente ida. Entonces salimos de la iglesia mayor, y yo tras él, y muy devotamente le vi oír misa y los otros oficios divinos, hacho tan pequeño tal ruindad!\", y reían mucho el artificio, y decíanle: \n",
        "```\n",
        "### Observaciones\n",
        "Se nota mejor con la temperatura un poco elevada. Tiene menos frases tomadas directo del texto, se nota una buena estructura dialogo/descripción, y las oraciones tienen son gramáticamente correctas. Tiene algunos errores, no es tan coherente como el texto original y no suenan naturales muchas de las oraciones, pero es una generación fiel al estilo del texto original."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
