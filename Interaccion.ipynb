{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab0afa1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1cd09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9104d9c",
   "metadata": {},
   "source": [
    "### Declaración funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e91ae352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función build_model usada en los notebooks\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size,\n",
    "                        output_dim=embedding_dim,\n",
    "                        ))\n",
    "    model.add(LSTM(rnn_units,\n",
    "                    return_sequences=True,\n",
    "                    stateful=True,\n",
    "                    recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(vocab_size))\n",
    "    return model\n",
    "\n",
    "# Función generate_text adaptada para recibir los parámetros necesarios\n",
    "def generate_text(model, start_string, char2idx, idx2char):\n",
    "    num_generate = 250\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    temperature = 0.3 \n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, \"reset_states\"):\n",
    "            layer.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n",
    "# Función filtrar_texto para \"limpiar\" el texto antes de pasarlo a otro modelo, para que no haya un conflicto de vo\n",
    "def filtrar_texto(texto, vocab):\n",
    "    texto_filtrado = ''.join(c for c in texto if c in vocab)\n",
    "    return texto_filtrado if texto_filtrado.strip() else \"Que te parece?\"\n",
    "\n",
    "# FUnción extraer_ultima_frase para extraer lo ultimo que dijo cada modelo antes de que el siguiente conteste\n",
    "def extraer_ultima_frase(texto):\n",
    "    frases = re.split(r'[,.]', texto.strip())\n",
    "    if len(frases) == 0:\n",
    "        return texto\n",
    "    else:\n",
    "        return frases[-1].strip() + '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8789ff",
   "metadata": {},
   "source": [
    "### (Re)construcción de los modelos\n",
    "Definiciones para utilizarse en la generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19aef8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabs sacados del print(vocab) del notebook correspondiente a cada modelo\n",
    "vocab_celestina = ['\\n', ' ', '!', '\"', '#', '&', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '{', '}', '~', '¡', '¿', 'Ü', 'á', 'ç', 'é', 'í', 'ñ', 'ó', 'ú']\n",
    "char2idx_celestina = {u:i for i, u in enumerate(vocab_celestina)}\n",
    "idx2char_celestina = np.array(vocab_celestina)\n",
    "embedding_dim_celestina = 256  # o el que usaste\n",
    "rnn_units_celestina = 1024\n",
    "\n",
    "vocab_lazarillo = ['\\n', '\\r', ' ', '!', '\"', '(', ')', ',', '-', '.', '1', '4', '5', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '{', '}', '¡', '«', '»', '¿', 'É', 'á', 'é', 'ê', 'í', 'ñ', 'ó', 'ú', 'ü'] \n",
    "char2idx_lazarillo = {u:i for i, u in enumerate(vocab_lazarillo)}\n",
    "idx2char_lazarillo = np.array(vocab_lazarillo)\n",
    "embedding_dim_lazarillo = 256\n",
    "rnn_units_lazarillo = 1024\n",
    "\n",
    "vocab_quijote = ['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', '«', '»', '¿', 'Á', 'É', 'Í', 'Ó', 'Ú', 'à', 'á', 'é', 'í', 'ï', 'ñ', 'ó', 'ù', 'ú', 'ü'] \n",
    "char2idx_quijote = {u:i for i, u in enumerate(vocab_quijote)}\n",
    "idx2char_quijote = np.array(vocab_quijote)\n",
    "embedding_dim_quijote = 256\n",
    "rnn_units_quijote = 1024\n",
    "\n",
    "# Construcción y carga pesos para cada modelo\n",
    "model_celestina = build_model(len(vocab_celestina), embedding_dim_celestina, rnn_units_celestina, batch_size=1)\n",
    "model_celestina.build(tf.TensorShape([1, None]))\n",
    "model_celestina.load_weights('model_celestina_100_2025.keras')\n",
    "\n",
    "model_lazarillo = build_model(len(vocab_lazarillo), embedding_dim_lazarillo, rnn_units_lazarillo, batch_size=1)\n",
    "model_lazarillo.build(tf.TensorShape([1, None]))\n",
    "model_lazarillo.load_weights('model_lazarillo_100_2025.keras')\n",
    "\n",
    "model_quijote = build_model(len(vocab_quijote), embedding_dim_quijote, rnn_units_quijote, batch_size=1)\n",
    "model_quijote.build(tf.TensorShape([1, None]))\n",
    "model_quijote.load_weights('model_quijote_100_2025.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03552994",
   "metadata": {},
   "source": [
    "### Diálogo\n",
    "A cada modelo, salvo la primera vez que se utiliza el texto inicial, se le da lo último que dijo el modelo anterior. Este fragmento se usa como start_string, y el modelo se lo cuestiona, para hacer que fluya el diálogo.\n",
    "\n",
    "**Ejemplo**:\n",
    "\n",
    "Si Celestina dice: *\"Baxa a él y dile que se pare.\"*\n",
    "\n",
    "Lazarillo le responde: *\"Baxa a él y dile que se pare? sin comer bocado, ni hablaba palabra...\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b298278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turno 1 ========================================================================================================================================================================================================\n",
      "Celestina:  Melibea, hija, ¿qué nueva me traes que vienes tan turbada?\n",
      "Espantados traygo estas formas de pesces, ino !\n",
      "kesí por me viuo con la Remano de\n",
      "vosotros, no sé si orejas mias, que jamás propento, en que con\n",
      "acordado cresciendo de vosotros sonos y acostados y lenguajes. ¿ Que me entendo sé\n",
      "qué se ha vestido su \n",
      "Lazarillo:  ¿ Que me entendo sé\n",
      "qué se ha vestido su?\"\n",
      "\n",
      "Y viejasastos mejor que un galgo suyo lo hiciera.\n",
      "\n",
      "Jue aktado la negra que llaman Oes{\", las cualendar mi amo y flegamerzüe el lasa, y no la cuieda la üencíaQÉ Él mes!\n",
      "\n",
      "\n",
      "\"Éste -decía yo-»» los por ko sin tienza ya la»z; y aun, as 15\n",
      "\n",
      "Respon\n",
      "Quijote:  as 15\n",
      "\n",
      "Respon?\n",
      "\n",
      "   Parte, es un caballero andante como un pasado, aunque no puede ser en\n",
      "creerla con quien acompañarse; pues si eso es así, como es uso y costumbre de los encantadores.\n",
      "\n",
      "Sancho respondió:\n",
      "\n",
      "-De todo lo que vuestra merced ha dicho y hecho ha de ser e\n",
      "Turno 2 ========================================================================================================================================================================================================\n",
      "Celestina:  Sancho respondió:\n",
      "\n",
      "-De todo lo que vuestra merced ha dicho y hecho ha de ser e?\n",
      "248. CEL. __ Locá, señor, no le despedazías lo que yo bien esto y contradezir a Celestina en quanto habla y, por impedir\n",
      "mi prouecho y el suyo, huelgas de no ganado con su muerte, con\n",
      "Santan a nosotros, contra los que ciñen espada,\n",
      "mostrá vn poco. ¡\n",
      "Lazarillo:  ¡?\"\n",
      "\n",
      "Tantas lábralos legancia a»xAstaba en la üersidad deL(RTula{ños: «Buenarme\n",
      "k¡Dios que me demediara! L}s semores de UZDes que abajara Grazón la}Zerás destabaxguestas villanos, porque, cierro a}M; mas esüé manera lamegqueño; lo séZis. Con é«\n",
      "\n",
      "\n",
      "\n",
      "Quijote:  Con é«?\n",
      "\n",
      "-Digo que si lo seréis algunos hombres las leyes y las desventuras, no te dejes cuenta; pero, como dicen que la soledad del\n",
      "puesto traía; y cuando llegaron a la voluntad de Sancho, le dijo:\n",
      "\n",
      "-¡Oh tú, quienquiera que seas, atres mil y trecientos azo\n",
      "Turno 3 ========================================================================================================================================================================================================\n",
      "Celestina:  atres mil y trecientos azo? Entre las puertas. ¡ O traydor de mí ! ! En qué gran faes él holgara con la vista de\n",
      "otras como él, que con la nuestra. Boluamos, por Dios, que me fino en\n",
      "ver yo fazer. Lastimado serás\n",
      "vester; assí se está noche el continuo trabajo; vna\n",
      "continua got\n",
      "Lazarillo:  Lastimado serás\n",
      "vester; assí se está noche el continuo trabajo; vna\n",
      "continua got? _ pobres 15554.\n",
      "\n",
      "Otro semente sadiendo ya que en toda su fuerza arremeste «Quas el contrario, ser cabul fiere» sugo axtos(ar los gares la casa y no laña gara la Mancha, que se dice, adonde topamos otros fue azuexlos llegarecie_\n",
      "\n",
      "\"¡Qué por buenas\n",
      "Quijote:  adonde topamos otros fue azuexlos llegarecie\n",
      "\n",
      "\"¡Qué por buenas?\n",
      "\n",
      "-No, no -replicó la duquesa-, señor don Quijote, que no hay duda en el cielo que guardan y miran el\n",
      "cuerpo con sus desvanecidos los ojos de vuestra merced y de mi mal\n",
      "aposejado, y los despajaos, amigos tenían como las del mundo, y vuelva a prosegui\n",
      "Turno 4 ========================================================================================================================================================================================================\n",
      "Celestina:  y vuelva a prosegui?\n",
      "119. CEL. __ ¡ Hijo de agora me entender en lo mejor y\n",
      "constrir no consiguirán ningún empocho sus Pármeno, De los fortunigos.\n",
      "110. SEMP. __ Déxala, que él con su pecho con las ceuos\n",
      "de nuestro estado, no tenga cuallo de yr con nuestra casa; en esto \n",
      "Lazarillo:  no tenga cuallo de yr con nuestra casa; en esto? Tentórasemante}}\n",
      "\n",
      "Élas kuncas y tentórron»¡\n",
      "\"Que5lándose, como ki4- no que aguje Justo,»S) el jarrazo con la muna pera la beremenar deñor so su1ño (míkes.-, buscando calor, irse a las cunas donde están criaturas y año ensanderan(eñor tantas les d\n",
      "Quijote:  irse a las cunas donde están criaturas y año ensanderan(eñor tantas les d?\n",
      "\n",
      "-No me puedo detener, señor -respondió don Quijote-, y aun de mis hijos; y, aunque los hicieron de algunas medicinas,\n",
      "que no se pueden ni deben ser muchos.\n",
      "\n",
      "-Así es la verdad -respondió la duquesa-, señor don Quijote, si no me puedes apartar dél, s\n",
      "Turno 5 ========================================================================================================================================================================================================\n",
      "Celestina:  s? Herode, los menosprecios, en viendo que de alguno eran\n",
      "amadas. Las quales, avnque están abrasadas y encendidas; juntas nos tantas tales\n",
      "tiembros del señor señora, cuydado venía ? ¿ Has llorado está el que le daxo.\n",
      "{384\"} Y en la tiene orden, como se\n",
      "Lazarillo:  como se?\"\n",
      "\n",
      "\"Verdad es_» -dijo yo- que en este manterentoJdecía salía Noküalegó y sacón del agua y día, porque de moce enE; y aunque hace poca, te lugar; y también sufrí; mas en las cosas que con él pasó\n",
      "\n",
      "\n",
      "\n",
      "Otro día, no pareciéndome estar allí seguro, f\n",
      "Quijote:  f? cual la verdad se aclarase, dijo:\n",
      "\n",
      "-¡Oh hideputa bellaco? ¿A buena fe que ha muchos días que la vez primero le viere salir de mi casa, aunque no fuera mujer más principal y hermosura de una dueña tan\n",
      "confusa y tan mal sufrido y de todo su cae\n",
      "   en \n"
     ]
    }
   ],
   "source": [
    "# Texto inicial para iniciar el diálogo\n",
    "texto = \"Melibea, hija, ¿qué nueva me traes que vienes tan turbada?\"\n",
    "\n",
    "# Número de turnos (cada modelo genera en secuencia)\n",
    "turnos = 5\n",
    "\n",
    "for i in range(turnos):\n",
    "    print(f\"Turno {i+1} {'='*200}\")\n",
    "\n",
    "    # responde celestina\n",
    "    respuesta_celestina = generate_text(model_celestina, texto, char2idx_celestina, idx2char_celestina)\n",
    "    print(\"Celestina: \", respuesta_celestina)\n",
    "\n",
    "    # se prepara lazarillo \n",
    "    texto = extraer_ultima_frase(respuesta_celestina)\n",
    "    texto = filtrar_texto(texto, vocab_lazarillo)\n",
    "\n",
    "    # responde lazarillo\n",
    "    respuesta_lazarillo = generate_text(model_lazarillo, texto, char2idx_lazarillo, idx2char_lazarillo)\n",
    "    print(\"Lazarillo: \", respuesta_lazarillo)\n",
    "\n",
    "    # se prepara quijote\n",
    "    texto = extraer_ultima_frase(respuesta_lazarillo)\n",
    "    texto = filtrar_texto(texto, vocab_quijote)\n",
    "\n",
    "    # responde quijote\n",
    "    respuesta_quijote = generate_text(model_quijote, texto, char2idx_quijote, idx2char_quijote)\n",
    "    print(\"Quijote: \", respuesta_quijote)\n",
    "\n",
    "    # se prepara celestina\n",
    "    texto = extraer_ultima_frase(respuesta_quijote)\n",
    "    texto = filtrar_texto(texto, vocab_celestina)\n",
    "\n",
    "    # print(\"=\"*300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89870617",
   "metadata": {},
   "source": [
    "Aunque técnicamente funciona, el resultado es lingüísticamente caótico y la coherencia se degrada rápidamente. Poniendo a charlar a los modelos, se puede ver que no hay coherencia en lo que dicen o en lo que se contestan, pero tampoco se puede esperar coherencia narrativa entre tres modelos entrenados por separado con datasets de estilo muy diferente. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
