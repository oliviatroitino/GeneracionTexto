{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_ahxalS_tMt"
      },
      "source": [
        "## Setup paquetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CyLNCN5Q8jNE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Opcional: Montar google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-dPaX2C_xSW"
      },
      "source": [
        "## Descarga y preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H9BVBBiB4ZK"
      },
      "source": [
        "Hay cambios del notebook de partida (de encoding `utf-8` a `latin-1`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duysNv6Y_ztb",
        "outputId": "47788265-a579-4ae8-ef46-083cd647d244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longitud del texto:        2071308 carácteres\n",
            "El texto está compuesto de estos 90 carácteres:\n",
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', '«', '»', '¿', 'Á', 'É', 'Í', 'Ó', 'Ú', 'à', 'á', 'é', 'í', 'ï', 'ñ', 'ó', 'ù', 'ú', 'ü']\n"
          ]
        }
      ],
      "source": [
        "# texto = open(\"/content/gdrive/MyDrive/Colab Notebooks/quijote.txt\", 'rb').read().decode(encoding='latin-1') # Para uso con google drive\n",
        "texto = open(\"3_textos_literatura_española/quijote.txt\", 'rb').read().decode(encoding='utf-8')\n",
        "print('Longitud del texto:        {} carácteres'.format(len(texto)))\n",
        "\n",
        "vocab = sorted(set(texto))\n",
        "\n",
        "print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n",
        "print (vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sZ3XIMVCFdh"
      },
      "source": [
        "### Procesamiento de los textos\n",
        "#### Mapeo de caracteres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of1auErLCHFP",
        "outputId": "0dafa0fd-89b5-4890-f5c5-d5e74b644b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '\"' :   3,\n",
            "  \"'\" :   4,\n",
            "  '(' :   5,\n",
            "  ')' :   6,\n",
            "  ',' :   7,\n",
            "  '-' :   8,\n",
            "  '.' :   9,\n",
            "  '0' :  10,\n",
            "  '1' :  11,\n",
            "  '2' :  12,\n",
            "  '3' :  13,\n",
            "  '4' :  14,\n",
            "  '5' :  15,\n",
            "  '6' :  16,\n",
            "  '7' :  17,\n",
            "  ':' :  18,\n",
            "  ';' :  19,\n",
            "  '?' :  20,\n",
            "  'A' :  21,\n",
            "  'B' :  22,\n",
            "  'C' :  23,\n",
            "  'D' :  24,\n",
            "  'E' :  25,\n",
            "  'F' :  26,\n",
            "  'G' :  27,\n",
            "  'H' :  28,\n",
            "  'I' :  29,\n",
            "  'J' :  30,\n",
            "  'L' :  31,\n",
            "  'M' :  32,\n",
            "  'N' :  33,\n",
            "  'O' :  34,\n",
            "  'P' :  35,\n",
            "  'Q' :  36,\n",
            "  'R' :  37,\n",
            "  'S' :  38,\n",
            "  'T' :  39,\n",
            "  'U' :  40,\n",
            "  'V' :  41,\n",
            "  'W' :  42,\n",
            "  'X' :  43,\n",
            "  'Y' :  44,\n",
            "  'Z' :  45,\n",
            "  ']' :  46,\n",
            "  'a' :  47,\n",
            "  'b' :  48,\n",
            "  'c' :  49,\n",
            "  'd' :  50,\n",
            "  'e' :  51,\n",
            "  'f' :  52,\n",
            "  'g' :  53,\n",
            "  'h' :  54,\n",
            "  'i' :  55,\n",
            "  'j' :  56,\n",
            "  'l' :  57,\n",
            "  'm' :  58,\n",
            "  'n' :  59,\n",
            "  'o' :  60,\n",
            "  'p' :  61,\n",
            "  'q' :  62,\n",
            "  'r' :  63,\n",
            "  's' :  64,\n",
            "  't' :  65,\n",
            "  'u' :  66,\n",
            "  'v' :  67,\n",
            "  'x' :  68,\n",
            "  'y' :  69,\n",
            "  'z' :  70,\n",
            "  '¡' :  71,\n",
            "  '«' :  72,\n",
            "  '»' :  73,\n",
            "  '¿' :  74,\n",
            "  'Á' :  75,\n",
            "  'É' :  76,\n",
            "  'Í' :  77,\n",
            "  'Ó' :  78,\n",
            "  'Ú' :  79,\n",
            "  'à' :  80,\n",
            "  'á' :  81,\n",
            "  'é' :  82,\n",
            "  'í' :  83,\n",
            "  'ï' :  84,\n",
            "  'ñ' :  85,\n",
            "  'ó' :  86,\n",
            "  'ù' :  87,\n",
            "  'ú' :  88,\n",
            "  'ü' :  89,\n"
          ]
        }
      ],
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlXmg61nDxFT"
      },
      "source": [
        "Pasamos cada texto a un array de enteros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IHo-ePmDwih",
        "outputId": "5003a515-d2e9-4a0c-bf24-2c9b1adaab1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "texto : 'El ingenioso hidalgo don Quijote de la Mancha\\n\\n\\nPr'\n",
            "'El ingenioso hidalgo don Quijote de la Mancha\\n\\n\\nPr'\n"
          ]
        }
      ],
      "source": [
        "text_as_int = np.array([char2idx[c] for c in texto])\n",
        "\n",
        "print ('texto : {}'.format(repr(texto[:50])))\n",
        "print ('{}'.format(repr(texto[:50])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMTjafW0Eaz2"
      },
      "source": [
        "### Preparación de los datos para entrenar la RNN\n",
        "\n",
        "Para entrenar el modelo creamos un conjunto de datos con el contenido de text_as_init. Para ello utilizamos la función tf.data.Dataset.from_tensor_slices.\n",
        "A este conjunto de datos lo dividiremos en secuencias de seq_length+1 al aplicar el método batch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9gOSC4lCFY8y"
      },
      "outputs": [],
      "source": [
        "# Creamos una función `split_input_target` que devolverá el conjunto de datos\n",
        "# de entrenamiento (los datos de entrada como los datos de salida)\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "#Agrupamos los dataset en batches de 64 .\n",
        "# Así tendriamos los datos de entrenamiento con batches compuestos de 64 parejas\n",
        "# de secuencias de 100 integers de 64 bits\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv39xu08EfGl",
        "outputId": "32d66c64-54a2-4596-e5dd-5269b60cf66e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'El ingenioso hidalgo don Quijote de la Mancha\\n\\n\\nPrimera parte del ingenioso hidalgo don Quijote de la'\n",
            "' Mancha\\n\\nCapítulo primero. Que trata de la condición y ejercicio del famoso hidalgo\\ndon Quijote de la'\n",
            "' Mancha\\n\\n\\nEn un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\\ntiempo que vivía '\n",
            "'un hidalgo de los de lanza en astillero, adarga antigua,\\nrocín flaco y galgo corredor. Una olla de al'\n",
            "'go más vaca que carnero,\\nsalpicón las más noches, duelos y quebrantos los sábados, lantejas los\\nviern'\n",
            "'es, algún palomino de añadidura los domingos, consumían las tres\\npartes de su hacienda. El resto dell'\n",
            "'a concluían sayo de velarte, calzas de\\nvelludo para las fiestas, con sus pantuflos de lo mesmo, y los'\n",
            "' días de\\nentresemana se honraba con su vellorí de lo más fino. Tenía en su casa una\\nama que pasaba de'\n",
            "' los cuarenta, y una sobrina que no llegaba a los veinte,\\ny un mozo de campo y plaza, que así ensilla'\n",
            "'ba el rocín como tomaba la\\npodadera. Frisaba la edad de nuestro hidalgo con los cincuenta años; era d'\n",
            "\n",
            "\n",
            "\n",
            "Input data:  'El ingenioso hidalgo don Quijote de la Mancha\\n\\n\\nPrimera parte del ingenioso hidalgo don Quijote de l'\n",
            "Target data: 'l ingenioso hidalgo don Quijote de la Mancha\\n\\n\\nPrimera parte del ingenioso hidalgo don Quijote de la'\n",
            "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n",
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "seq_length = 100\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))\n",
        "\n",
        "#Aplicamos split_input_target a todas las secuencias utilizando el método map()\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Los dataset contienen un conjunto de parejas (100 caracteres del texto original, la correspondiente salida ). Vamos a mostrar la primera pareja.\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))\n",
        "\n",
        "  print(dataset)\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print (dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzc_abq3Gtra"
      },
      "source": [
        "### Construcción del modelo RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "s9Uxb2ALG0kv"
      },
      "outputs": [],
      "source": [
        "#Crearemos una función que cree un modelo RNN con tres capas\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = Sequential()\n",
        "  #Añadimos la capa de tipo word embedding\n",
        "  model.add(Embedding(input_dim=vocab_size,\n",
        "                      output_dim=embedding_dim,\n",
        "                      #batch_input_shape=[batch_size, None] Deprecated\n",
        "                      ))\n",
        "  #Añadimos la capa de tipo LSTM\n",
        "  model.add(LSTM(rnn_units,\n",
        "                 return_sequences=True,\n",
        "                 stateful=True,\n",
        "                 recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "  #Añadimos la capa de tipo Dense\n",
        "  model.add(Dense(vocab_size))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CXSrXhXHG-Vh"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "YkxLgKFMHLoB",
        "outputId": "1db8e76d-af40-477c-8ce5-e96ac9bd4cc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH80YLm9IC5O",
        "outputId": "acf83d8b-84c8-4518-9486-752cc981fa28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: (64, 100) # (batch_size, sequence_length)\n",
            "Target: (64, 100) # (batch_size, sequence_length)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n",
        "  print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfJiDVjVIFMx",
        "outputId": "917711c3-88c2-4718-a387-8a1c1be8c3d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction :  (64, 100, 90) # (batch_size, sequence_length, vocab_size)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-24 22:35:24.664422: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(\"Prediction : \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "j8ODv1oxIGxL"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s5oc_-5Il7k",
        "outputId": "56449a95-1414-4463-fceb-0a070150b1aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 8 64 73 63 10 71  0 28 16 65 16 63  6 33 39 19 48  7 58  4 84 81 67  7\n",
            " 64  6 26 39 70  0 30  6  7 58 18 85 29 65 66 32 52 54 18 60 84 87 48 34\n",
            " 69 14 17 59 10 70 71 74 75 82 67 43 69 11 84 30 66 68 85  4 33 64 13 88\n",
            " 17 83 73 18  0 19 17 20 18 22 71 86 16 15  6 10 80 56 57 78 24 70 22 60\n",
            " 57 50  1  3]\n"
          ]
        }
      ],
      "source": [
        "print(sampled_indices_characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJENmFNXL0Io"
      },
      "source": [
        "### Entrenamiento del modelo RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "uKqSJOP_Cpso"
      },
      "outputs": [],
      "source": [
        "#Creamos la función de perdida, usaremos el categorical pues estamos considerando datos categóricos\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YPNOYQq9Cpu-"
      },
      "outputs": [],
      "source": [
        "#Compilamos el modelo\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qqxhp8m-Cpw1"
      },
      "outputs": [],
      "source": [
        "#configuramos los checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints_Quijote'\n",
        "\n",
        "# nombre fichero\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementación EarlyStopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=10,\n",
        "    min_delta=0.01,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SROaEjLNDCuF",
        "outputId": "6a8a26a2-a7a1-469c-d8ba-851eb773137f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 592ms/step - loss: 2.3630\n",
            "Epoch 2/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 621ms/step - loss: 1.6249\n",
            "Epoch 3/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 639ms/step - loss: 1.4342\n",
            "Epoch 4/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 661ms/step - loss: 1.3381\n",
            "Epoch 5/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 657ms/step - loss: 1.2780\n",
            "Epoch 6/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 639ms/step - loss: 1.2303\n",
            "Epoch 7/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 641ms/step - loss: 1.1921\n",
            "Epoch 8/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 643ms/step - loss: 1.1577\n",
            "Epoch 9/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 643ms/step - loss: 1.1277\n",
            "Epoch 10/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 649ms/step - loss: 1.0988\n",
            "Epoch 11/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 649ms/step - loss: 1.0711\n",
            "Epoch 12/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 651ms/step - loss: 1.0421\n",
            "Epoch 13/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 661ms/step - loss: 1.0143\n",
            "Epoch 14/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 675ms/step - loss: 0.9897\n",
            "Epoch 15/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 666ms/step - loss: 0.9613\n",
            "Epoch 16/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 709ms/step - loss: 0.9364\n",
            "Epoch 17/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 1s/step - loss: 0.9115\n",
            "Epoch 18/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37574s\u001b[0m 118s/step - loss: 0.8903\n",
            "Epoch 19/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 898ms/step - loss: 0.8654\n",
            "Epoch 20/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 567ms/step - loss: 0.8474\n",
            "Epoch 21/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 572ms/step - loss: 0.8246\n",
            "Epoch 22/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 585ms/step - loss: 0.8064\n",
            "Epoch 23/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 575ms/step - loss: 0.7900\n",
            "Epoch 24/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 574ms/step - loss: 0.7728\n",
            "Epoch 25/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 622ms/step - loss: 0.7587\n",
            "Epoch 26/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 595ms/step - loss: 0.7448\n",
            "Epoch 27/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 590ms/step - loss: 0.7322\n",
            "Epoch 28/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 591ms/step - loss: 0.7208\n",
            "Epoch 29/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 590ms/step - loss: 0.7096\n",
            "Epoch 30/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 613ms/step - loss: 0.6978\n",
            "Epoch 31/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 613ms/step - loss: 0.6890\n",
            "Epoch 32/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 628ms/step - loss: 0.6779\n",
            "Epoch 33/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 648ms/step - loss: 0.6717\n",
            "Epoch 34/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 607ms/step - loss: 0.6634\n",
            "Epoch 35/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 620ms/step - loss: 0.6535\n",
            "Epoch 36/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 691ms/step - loss: 0.6454\n",
            "Epoch 37/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 651ms/step - loss: 0.6389\n",
            "Epoch 38/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 656ms/step - loss: 0.6307\n",
            "Epoch 39/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 652ms/step - loss: 0.6266\n",
            "Epoch 40/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 633ms/step - loss: 0.6182\n",
            "Epoch 41/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 641ms/step - loss: 0.6152\n",
            "Epoch 42/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 649ms/step - loss: 0.6085\n",
            "Epoch 43/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 635ms/step - loss: 0.6029\n",
            "Epoch 44/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 630ms/step - loss: 0.5974\n",
            "Epoch 45/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 657ms/step - loss: 0.5915\n",
            "Epoch 46/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 683ms/step - loss: 0.5886\n",
            "Epoch 47/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 657ms/step - loss: 0.5825\n",
            "Epoch 48/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 647ms/step - loss: 0.5803\n",
            "Epoch 49/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 627ms/step - loss: 0.5746\n",
            "Epoch 50/50\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 616ms/step - loss: 0.5716\n"
          ]
        }
      ],
      "source": [
        "#Entrenamos el modelo\n",
        "EPOCHS=50\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback, early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "UwLoIf-eJNDH",
        "outputId": "2ab27dfd-127a-4716-e337-1e19232a4346"
      },
      "outputs": [],
      "source": [
        "model.save(\"model_quijote_100_2025.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Mk5PTDmwAqsJ"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras import losses # Import the losses module\n",
        "\n",
        "# Assuming your original loss function was, for example, binary_crossentropy\n",
        "loaded_model = load_model(\"model_quijote_100_2025.keras\",\n",
        "                          custom_objects={'loss': losses.sparse_categorical_crossentropy})\n",
        "# or if it was a custom loss function\n",
        "# loaded_model = load_model(\"model_paquita_100_2024.keras\", custom_objects={'loss': my_custom_loss_function})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = build_model(len(vocab), embedding_dim, rnn_units, batch_size=1)\n",
        "input_shape = (1, 100)  # Replace 100 with your actual sequence length\n",
        "model.build(input_shape=input_shape) # Or model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.load_weights(\"model_quijote_100_2025.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Creamos una función generar_texto que generará texto a partir de una palabra de partida\n",
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 1000\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "\n",
        "  # temperature = 0.7 # cuanto mas alto el numero, mas directa la salida de los logits\n",
        "  temperature = 0.2 # con 0.3 va mejor segun testeo con la otra clase, con 0.1 se vuelve repetitivo\n",
        "\n",
        "#  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "En un lugar de la Mancha, de cuyo nombre no quiero acordarme en\n",
            "volver tan al cielo abierto, pues tan saltres como el de\n",
            "Cardenio, que ya no estoy cansado de mentir todo mi voluntad y tal\n",
            "medro. Y, siendo yo la maldiciendo en que ella le había dado. Viéndole así\n",
            "dar a los dos que han de servir cuatro cocos de a caballo y de los atrevidos que la\n",
            "mercedes se hallan. Yo no he visto ni otra cosa de más de\n",
            "cuatro días, yo me estimo yo en mi casa, y por esto como por mi provecho. Yo, Sancho,\n",
            "bien criado, corazón de acompañar a la soledad de los nombres: a tiempo que la había de llevar al\n",
            "lugar de don Quijote, y así lo confirmó a buscar a don Quijote, por parecerle que se le\n",
            "desengañaba, de modo que la abriente la sala por los caminos podía\n",
            "ver más a menudo y todos los demás simplicidades que se debía a\n",
            "tiempo que la valentía y el de su señor había escuchado. Y, al\n",
            "querer verdad a lo que se le ha de hacer dellos, como vuestra merced lleva el conveniente rico, entre\n",
            "otras, muchos son las que ahora no han de hallar en ellas la verdad de la historia lo q\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"En un lugar de la Mancha, de cuyo nombre no quiero acordarme\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resultados, análisis y conclusiones\n",
        "\n",
        "## Intento 1: \n",
        "**50 Épocas y 0.3 de temperatura**\n",
        "```\n",
        "En un lugar de la Mancha, de cuyo nombre no quiero acordarme en ello, porque\n",
        "tenga fama de tan buena suerte, y amiga mía, a quien tiene lleno de memorias y\n",
        "las que le dieron con sus armas y caballo que se hallaba en Argel, edvierta sangre de la malicia del alma.\n",
        "   Tú te guardas, y que esta mañana me ha dado y\n",
        "escribiendo en la tabla del mundo. Y, porque no pierdas, Sancho me daré de que todos los de tu atrevimiento y\n",
        "su corazón hace, no se os ha caballero, y de los mejores muestran todos los días de mi vida?\n",
        "\n",
        "-Sí diré, pecador de mí, -replicó Sancho-, porque los buenos decir que eres, ya en este\n",
        "paracer, de hombre de caña, como mostraba el arroyo en mi espada, con la lanza son religiosas más estrechas aguas, y\n",
        "después me desembaraza, y así lo temió y dijo:\n",
        "\n",
        "-Señor mío, yo no debo de entender que no soy de dos libros menos simples que las han\n",
        "vengado, no nos descontara; pero, en fin, se halló en unas florestas trabajos y\n",
        "volverme a pedor de comer; y, como no la han dicho que de mí se debía de haber\n",
        "hecho alguna noche. Dulcinea es mi esposa, y l\n",
        "```\n",
        "### Observaciones\n",
        "Está bastante bien para un modelo entrenado poco. El tono es fiel a la obra original, mezcla frases que suenan naturales con otras que se le van un poco de las manos. Algunas partes son fluidas y se entiende lo que intenta decir, pero no llega a ser coherente. No repite tanto directo del original, pero todavía le cuesta mantener una idea.\n",
        "\n",
        "## Intento 2:\n",
        "**50 Épocas y 0.4 de temperatura**\n",
        "```\n",
        "En un lugar de la Mancha, de cuyo nombre no quiero acordarme de\n",
        "nodados bien las cosas.\n",
        "\n",
        "-Eso creo yo muy bien -respondió el bachille-, que no quiero llevar el licenciado de mis dueños, y\n",
        "a pesar sus labios, y que en el traje parece que con las virtudes tienen más\n",
        "de los que me conocen y conocen su mujer, sin que ha de tomar al que de llamarte es el\n",
        "que tengo de servirse, y comer alguna rodela al mayor concebido en los\n",
        "principios, con el pelo de la venta, que a él le pareció que\n",
        "todos los demás saltando con sus amigos sus padres, así como estaba, y al cual no le contentará lo que debo\n",
        "a mi señora, aunque no me lo pagare a ponerme en ella, y de algún grave acocida a quien esta noche\n",
        "ha he dicho, no se me ha de dar nada para que se los deje\n",
        "de decir otras noches las que aquí vienen que los reyes y profesión, que de la honestidad son de mi vida, a lo\n",
        "menos, estaré yo más escondida de mi muerte.\n",
        "\n",
        "-Desa manera -respondió don Quijote-, porque estos dos amigos me lo\n",
        "dije y acarrea de los reyes como las humildes chozas de la cabeza, y la\n",
        "doncella sube\n",
        "```\n",
        "\n",
        "### Observaciones\n",
        "Esta versión del modelo tiene un tono más creativo (temperatura más alta) y algunas frases que no tienen mucho sentido pero suenan del estilo del Quijote. Hay saltos temáticos abruptos y algunas partes no tienen ningún sentido."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
